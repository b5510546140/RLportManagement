{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Agent\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
    "        self.state_size = state_size # normalized previous days\n",
    "        self.action_size = 3 #  buy_1, sell_1,DO Nothing\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.inventory1 = []\n",
    "        self.inventory2 = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        self.gamma = 0.95 #gamma is the discount factor. It quantifies how much importance we give for future rewards.\n",
    "        self.epsilon = 1.0 #Exploration and Exploitation — Epsilon (ε)\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = load_model(\"models/\" + model_name) if is_eval else self._model()\n",
    "\n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "#             print(\"random action\")\n",
    "            return random.randrange(self.action_size)\n",
    "#         print(\"Calculating using model\")\n",
    "#         print(self.model.predict(state))\n",
    "        options = self.model.predict(state)\n",
    "#         print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "    \n",
    "    def getPredict(self, state):\n",
    "        print(\"Predict using model\")\n",
    "        options = self.model.predict(state)\n",
    "        print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "\n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "#         print(\"expReplay\")\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "#             print(\"For loop\")\n",
    "            target = reward\n",
    "#             print(\"target = \"+str(target))\n",
    "#             print(\"Done = \"+str(done))\n",
    "            if not done:\n",
    "#                 print(\"Not Done\")\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "#             print(\"target_f\")\n",
    "#             print(target_f)\n",
    "#             print(target_f[0][action])\n",
    "            target_f[0][action] = target\n",
    "#             print(target_f)\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "#             print(\"Self model\")\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "#         print(\"Wtf model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockDataVec(key):\n",
    "    vec = []\n",
    "    lines = open(\"data/\" + key + \".txt\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vec.append(float(line.split(\",\")[4]))\n",
    "\n",
    "    return vec\n",
    "\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockVolVec(key):\n",
    "    vol = []\n",
    "    lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vol.append(float(line.split(\",\")[5]))\n",
    "\n",
    "    return vol\n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "import numpy as np\n",
    "import random\n",
    "import math, random \n",
    "import gym \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, data1, Bal_stock1, open_cash, timestep):\n",
    "        self.Stock1Price=data1[timestep] #stock 1 open price\n",
    "        self.Stock1Blnc=Bal_stock1 #stock 1 balance\n",
    "        self.open_cash=open_cash #cash balance\n",
    "        self.fiveday_stock1=self.five_day_window(data1, timestep)\n",
    "        #self.volume1=volume1[timestep]\n",
    "        #self.volume2=volume2[timestep]\n",
    "        self.portfolio_value=self.portfolio_value()\n",
    "\n",
    "    def portfolio_value(self):\n",
    "        pvalue=0\n",
    "        #print(\"In portfolio func\")\n",
    "        #print(\"self.Stock1Price\",self.Stock1Price, type(self.Stock1Price))\n",
    "        #print(\"self.Stock1Blnc\",self.Stock1Blnc[0], type(self.Stock1Blnc))\n",
    "\n",
    "        v1=self.Stock1Price * float(self.Stock1Blnc)\n",
    "        v2=float(self.open_cash)\n",
    "        return (v1+v2)\n",
    "    \n",
    "    def next_opening_price(self):\n",
    "        return data1[timestep+1]\n",
    "    \n",
    "    def five_day_window(self,data, timestep):\n",
    "        step = timestep\n",
    "        if step < 5:\n",
    "            return data[0]\n",
    "        \n",
    "        stock_5days = np.mean(data[step-5:step])\n",
    "        #print(\"stock_5days=\" + str(stock_5days))\n",
    "        #print(stock_5days)\n",
    "\n",
    "        #print(type(stock_5days))\n",
    "\n",
    "        return stock_5days\n",
    "    \n",
    "    def reset(self):\n",
    "        #self.state = torch.FloatTensor(torch.zeros(8)).cuda()\n",
    "        self.Stock1Price=151.25 #stock 1 open price Google\n",
    "#         self.Stock2Price=21.845 #stock 2 open price Walmart\n",
    "        self.Stock1Blnc=34 #stock 1 balance Google\n",
    "#         self.Stock2Blnc=221 #stock 2 balance Walmart\n",
    "        self.open_cash=10000 #cash balance\n",
    "        self.fiveday_stock1=151.25\n",
    "#         self.fiveday_stock2=21.845\n",
    "        self.portfolio_value=10000\n",
    "        \n",
    "    def getState(self):\n",
    "        #print(\"In get state\")\n",
    "        res=[]\n",
    "        res.append(self.Stock1Price) #stock 1 open price\n",
    "#         res.append(self.Stock2Price) #stock 2 open price\n",
    "        res.append(self.Stock1Blnc) #stock 1 balance\n",
    "#         res.append(self.Stock2Blnc) #stock 2 balance\n",
    "        res.append(self.open_cash) #cash balance\n",
    "        res.append(self.fiveday_stock1)\n",
    "#         res.append(self.fiveday_stock2)        \n",
    "        res.append(self.portfolio_value)\n",
    "        #res.append(self.volume1)\n",
    "        #res.append(self.volume2)\n",
    "\n",
    "\n",
    "        \n",
    "        #print(res)\n",
    "        res1=np.array([res])\n",
    "        #print(\"res array\"+np.array([res]))\n",
    "        return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math, random \n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#stock_name, window_size, episode_count = sys.argv[1], int(sys.argv[2]), int(sys.argv[3])\n",
    "\n",
    "stock_name1, episode_count, start_balance, training, test = 'AOT.BK', 50,10000,600,500\n",
    "\n",
    "\n",
    "pd_data1=pd.read_csv('data/AOT.BK.csv', sep=\",\", header=0)\n",
    "# pd_data2=pd.read_csv('data/amzn.us.txt', sep=\",\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^\n"
     ]
    }
   ],
   "source": [
    "# if (pd_data1['Date'][0]>pd_data2['Date'][0]): \n",
    "#     #print(\"Date1 is older than Date2\")\n",
    "#     pd_data1=pd_data1[pd_data1.Date>=pd_data2['Date'][0]]\n",
    "#     pd_data1=pd_data1.reset_index(drop=True)\n",
    "# else:\n",
    "#     #print(\"Date2>Date1\")\n",
    "#     pd_data2=pd_data2[pd_data2.Date>=pd_data1['Date'][0]]\n",
    "#     pd_data2=pd_data2.reset_index(drop=True)\n",
    "    #print(\"Date2>Date1  and date2 is\" + str(pd_data2['Date'][0]) +\" Date 1 is : \"+ str(pd_data1['Date'][0]))\n",
    "print(\"^^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre -Processing the Datasheet ...Drop Data that is not in both stock data- some days data is missing in Apple and some in Amazon\n",
    "import datetime\n",
    "#timestamp = data1_date[10]\n",
    "#print(timestamp.strftime('%Y-%m-%d'))\n",
    "#Convert  Date to Date format\n",
    "pd_data1['Date']=pd.to_datetime(pd_data1['Date'], format='%Y/%m/%d')\n",
    "# pd_data2['Date']=pd.to_datetime(pd_data2['Date'], format='%Y/%m/%d')\n",
    "\n",
    "list1= pd_data1['Date']\n",
    "# list2= pd_data2['Date']\n",
    "# diff_pd1_data = list(set(list1) - set(list2))\n",
    "# diff_pd2_data = list(set(list2) - set(list1))\n",
    "#x11=x[0].strftime('%Y-%m-%d 00:00:00')\n",
    "#p=datetime.datetime.strptime(x11, \"%Y-%m-%d 00:00:00\")\n",
    "#print(p)\n",
    "# for k in range(len(diff_pd1_data)):\n",
    "#     pd1_dat_format=diff_pd1_data[k].strftime('%Y-%m-%d 00:00:00')\n",
    "#     date_format_pd1=datetime.datetime.strptime(pd1_dat_format, \"%Y-%m-%d 00:00:00\")\n",
    "#     for i, j in enumerate(list1):\n",
    "#         if j == date_format_pd1:\n",
    "#             #print(i)\n",
    "#             pd_data1=pd_data1.drop([i])            \n",
    "# pd_data1=pd_data1.reset_index(drop=True)\n",
    "\n",
    "# for k in range(len(diff_pd2_data)):\n",
    "#     pd2_dat_format=diff_pd2_data[k].strftime('%Y-%m-%d 00:00:00')\n",
    "#     date_format_pd2=datetime.datetime.strptime(pd2_dat_format, \"%Y-%m-%d 00:00:00\")\n",
    "#     for M, N in enumerate(list2):\n",
    "#         if N == date_format_pd2:\n",
    "#             #print(M)\n",
    "#             pd_data2=pd_data2.drop([M])\n",
    "            \n",
    "# pd_data2=pd_data2.reset_index(drop=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "pd_data1_train=pd_data1[0:training]\n",
    "# pd_data2_train=pd_data2[0:training]\n",
    "#Test Data\n",
    "pd_data1_test=pd_data1[training:training+test]\n",
    "# pd_data2_test=pd_data2[training:training+test]\n",
    "\n",
    "\n",
    "\n",
    "vol1_train=getStockVolVec(stock_name1)\n",
    "# vol2_train=getStockVolVec(stock_name2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Stock AOT.BK = 17.0 unit\n",
      "Benchmark_Profit is  11607.600068with Apple Stocks:  8.0\n"
     ]
    }
   ],
   "source": [
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "\n",
    "# total_Prof=[]\n",
    "# done=False\n",
    "\n",
    "#Benchmark Model\n",
    "#In this model, we would divide \n",
    "\n",
    "\n",
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "#print(df_data1)\n",
    "total_Prof=[]\n",
    "done=False\n",
    "\n",
    "Act_datasize = training\n",
    "batch_size = 64\n",
    "\n",
    "#Benchmark Model\n",
    "\n",
    "data1_train=pd_data1_train['Open']\n",
    "# data2_train=pd_data2_train['Open']\n",
    "\n",
    "data1_date=pd_data1_train['Date']\n",
    "# Start with half of money bought stock1\n",
    "Act_Bench_Stock1_Bal=int(np.floor((start_balance/2)/data1_train[0]))\n",
    "# Act_Bench_Stock2_Bal=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "Act_Bench_Open_cash=start_balance/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Program to calculate benchmark profit\n",
    "\n",
    "\n",
    "#sell 10% of stock in 10 intervals\n",
    "#Example 100 days of data set.Sold every 10 days of 10%.\n",
    "\n",
    "interval=int(Act_datasize/10)\n",
    "Total_Stock1_Amount= Act_Bench_Stock1_Bal\n",
    "# Total_Stock2_Amount= 0\n",
    "stocks2Value = 0\n",
    "# stocks1Value = 0\n",
    "\n",
    "Act_stocks1=np.floor(Act_Bench_Stock1_Bal /10)\n",
    "# Act_stocks2=np.floor(Act_Bench_Stock2_Bal /10)\n",
    "print(\"Buy Stock \"+stock_name1+\" = \"+str(Act_stocks1)+\" unit\")\n",
    "# print(str(Act_stocks2))\n",
    "\n",
    "remaining_stock1=Act_Bench_Stock1_Bal\n",
    "# remaining_stock2=Act_Bench_Stock2_Bal\n",
    "ttl=0\n",
    "\n",
    "Benchmark_Port_Value=[]\n",
    "\n",
    "\n",
    "for j in range (interval,Act_datasize+1,interval):\n",
    "        #print(\"closing prices : \" + str(data1_train[j-1]) )\n",
    "        Price_closing_Stock1=data1_train[j-1]\n",
    "#         Price_closing_Stock2=data2_train[j-1]\n",
    "        \n",
    "        date_stock1=data1_date[j-1].strftime('%Y-%m-%d')\n",
    "        #print(date_stock1)\n",
    "                \n",
    "        stocks1Value= Act_stocks1 * Price_closing_Stock1\n",
    "#         stocks2Value= Act_stocks2 * Price_closing_Stock2\n",
    "        remaining_stock1=remaining_stock1-Act_stocks1\n",
    "#         remaining_stock2=remaining_stock2-Act_stocks2\n",
    "        #print(\"J is:\"+ str(j))\n",
    "        \n",
    "        \n",
    "        \n",
    "        Stock1_Port_value=remaining_stock1*Price_closing_Stock1\n",
    "#         Stock2_Port_value=remaining_stock2*Price_closing_Stock2\n",
    "        Act_Bench_Open_cash=Act_Bench_Open_cash+stocks1Value+stocks2Value #Adding 10% sold value into open cash\n",
    "        \n",
    "        Total_Portfolio_value=Act_Bench_Open_cash+Stock1_Port_value\n",
    "        Benchmark_Port_Value.append([date_stock1,Total_Portfolio_value])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#print (\"total_Test_Benchmark_amount : \" +  str(Total_Portfolio_value))\n",
    "\n",
    "Training_Benchmark_Portfolio_Value= Total_Portfolio_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(Training_Benchmark_Portfolio_Value) +\"with Apple Stocks:  \" + str(remaining_stock1))\n",
    "\n",
    "\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialize Agent\n",
    "# agent = Agent(5)\n",
    "# Bal_stock1=int(0)\n",
    "# open_cash=start_balance\n",
    "    \n",
    "# datasize=training\n",
    "# reward = 0\n",
    "# state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# state_array_obj=state_class_obj.getState()\n",
    "# action = agent.act(state_array_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Initialize Agent\n",
    "# # agent = Agent(5)\n",
    "# # Bal_stock1=int(0)\n",
    "# # open_cash=start_balance\n",
    "    \n",
    "# # datasize=training\n",
    "# # reward = 0\n",
    "# # state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# # state_array_obj=state_class_obj.getState()\n",
    "# # action = agent.act(state_array_obj)\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))\n",
    "# print(\"Action =\"+ str(action))\n",
    "# print(agent.getPredict(state_array_obj))\n",
    "# next_state_class_obj=State(data1_train, Bal_stock1, open_cash,1)\n",
    "# next_state_array_obj=next_state_class_obj.getState()\n",
    "# print(\"..........\")   \n",
    "# #                          state, action, reward, next_state, done\n",
    "# agent.memory.append((state_array_obj, 1, -500000, next_state_array_obj, True))\n",
    "# # agent.expReplay(len(agent.memory))\n",
    "# print(agent.getPredict(next_state_array_obj))\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 18:05:56.230599 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0902 18:05:56.242340 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0902 18:05:56.244163 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0902 18:05:56.291123 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0902 18:05:56.320269 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0902 18:05:56.321623 4618237376 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 0/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 1/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 2/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 3/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 4/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 5/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 6/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 7/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 8/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 9/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 10/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 11/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 12/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 13/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 14/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 15/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 16/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 17/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 18/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 19/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 20/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 21/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 22/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 23/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 24/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 25/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 26/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 27/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 28/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 29/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 30/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 31/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 32/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 33/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 34/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 35/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 36/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 37/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 38/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 39/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 40/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 41/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 42/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 43/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 44/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 45/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 46/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 47/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 48/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 49/50\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 50/50\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"..........\")\n",
    "    print(\"Episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    \n",
    "#     Bal_stock1=int(0)\n",
    "    Bal_stock1 = int(np.floor((start_balance/2)/data1_train[0]))\n",
    "#     Bal_stock2=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "    open_cash=start_balance/2\n",
    "    datasize=training\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "    agent = Agent(5)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "#     agent.inventory2 =[]\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "#     for i in range(Bal_stock2):\n",
    "#         agent.inventory2.append(data2_train[0]) \n",
    "    \n",
    "    \n",
    "    #Timestep delta to make sure that with time reward increases for taking action\n",
    "    #timestep_delta=0\n",
    "    \n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "        action = agent.act(state_array_obj)\n",
    "                   \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "                reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "                #needs to be reviewed\n",
    "                if(state_class_obj.open_cash<500):\n",
    "                    reward=-1000\n",
    "                elif (state_class_obj.Stock1Price > state_class_obj.fiveday_stock1):\n",
    "                    reward=abs(state_class_obj.Stock1Price - state_class_obj.fiveday_stock1)*100\n",
    "                    if(Bal_stock1_t1 == 1):\n",
    "                        reward = 30000\n",
    "                else:  \n",
    "                    reward=-change_percent_stock1*100\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:  \n",
    "#                     reward=-change_percent_stock1*100\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "                reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "          \n",
    "                if(state_class_obj.Stock1Blnc<10):\n",
    "                    reward=-100000\n",
    "                elif (abs(change_percent_stock1)<=2):\n",
    "                    reward=-1000\n",
    "                else:\n",
    "                    reward=change_percent_stock1*100 #State[0] is the price of stock 1. Here we are buying 1 stock\n",
    "                \n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action    \n",
    "                if (abs(change_percent_stock1)<=2):\n",
    "                    reward=100\n",
    "                elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "                    reward=-1000000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "                \n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "        \n",
    "        \n",
    "#         if action == 3:  #buy stock 2\n",
    "#             if state_class_obj.Stock2Price > state_class_obj.open_cash:\n",
    "#                 '''\n",
    "#                 print(\"Buy stock 2 when it did not have cash, so bankrupt, end of episode\")\n",
    "#                 reward=-reward_timedelta*10\n",
    "#                 done = True\n",
    "                \n",
    "#                 '''\n",
    "#                 #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "#                 #it should pick from other actions\n",
    "#                 #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "#                  #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "#                 #else:    \n",
    "#                 #print(\"Bankrupt\")\n",
    "#                 reward=-200000\n",
    "#                 done = True\n",
    "#                      #end episode   \n",
    "#             else:\n",
    "#                 #print(\"In Buy stock 2\")\n",
    "#                 agent.inventory2.append(data2_train[t])\n",
    "#                 Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "#                 open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock2Price\n",
    "                \n",
    "#                 if(state_class_obj.open_cash<5000):\n",
    "#                     reward=-100000\n",
    "#                 elif (abs(change_percent_stock2)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:\n",
    "#                     reward=-change_percent_stock2*100\n",
    " \n",
    "        \n",
    "#         if action == 4:  #sell stock 2\n",
    "#             if state_class_obj.Stock2Blnc <1 :\n",
    "#                     #print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "#                     reward=-200000\n",
    "#                     done = True\n",
    "#                 #end episode\n",
    "#             else:\n",
    "#                 #print(\"In sell stock 2\")\n",
    "#                 bought_price2=agent.inventory2.pop(0)\n",
    "#                 Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "#                 open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock2Price\n",
    "    \n",
    "              \n",
    "#                 if(state_class_obj.Stock2Blnc<10):\n",
    "#                     reward=-100000\n",
    "#                 elif (abs(change_percent_stock2)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:\n",
    "#                     reward=change_percent_stock2*100 \n",
    "                \n",
    "                \n",
    "#                 total_profit += state_class_obj.Stock2Price - bought_price2\n",
    "\n",
    "#                # print(\"reward for selling stock2: \" + str(reward))\n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            #print(\"--------------------------------\")\n",
    "           # print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "           # print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "           # print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \n",
    "             #     \"  stock 1 number: \" + str(len(agent.inventory1))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "\n",
    "            total_Prof.append(total_profit)\n",
    "            total_stock1bal.append(len(agent.inventory1))\n",
    "#             total_stock2bal.append(len(agent.inventory2))\n",
    "            total_open_cash.append(state_class_obj.open_cash)\n",
    "            total_port_value.append(state_class_obj.portfolio_value)\n",
    "            total_days_played.append(t)\n",
    "            if len(agent.memory) <= batch_size:\n",
    "                print(\"^_^\")\n",
    "                agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)\n",
    "\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        agent.model.save(\"models/model_ep\" + str(e)+\".h5\")\n",
    "        \n",
    "\n",
    "        \n",
    "#print(\"Total Apple stocks in episodes\"+ str(total_stock1bal))\n",
    "#print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "#print(\"Total Open cash in episodes\"+ str(total_open_cash))\n",
    "#print(\"Total Portfolio value in episodes\"+ str(total_port_value))\n",
    "#print(\"Total Days in episodes\"+ str(total_days_played))\n",
    "#print(\"Benchmark_Profit is  \" + str(int(Benchmark_Portfolio_Value)) +\"   with Apple Stocks: \" + str(Bench_Stock1_Bal) + \n",
    "    #  \"   and Amazon stocks: \"+ str(Bench_Stock2_Bal) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Apple stocks in episodes[247, 321, 324, 318, 316, 270, 310, 324, 316, 280, 210, 317, 228, 252, 321, 321, 237, 327, 169, 318, 256, 309, 318, 324, 233, 312, 310, 323, 311, 307, 283, 262, 185, 231, 254, 229, 319, 312, 294, 312, 246, 275, 323, 286, 325, 321, 290, 318, 314, 318, 324]\n",
      "///////\n",
      "Total Open cash in episodes[2410.749998000004, 26.899988000001755, 8.199994000002974, 31.2000050000008, 30.299983999997394, 1749.7999810000024, 5.050033999999869, 13.400006000001866, 3.399990000001253, 1462.1999960000019, 3791.499988999998, 28.400022000004824, 3197.1499880000024, 2121.0999829999987, 14.299989999996058, 9.750000000006594, 2988.499986000003, 22.00000099999947, 5247.200004, 2.2000240000001696, 2182.6000040000026, 2.0000249999987716, 2.7000159999986835, 7.799986999998609, 3027.1499899999976, 10.599997999998124, 9.699992999998685, 15.500014000005095, 31.899988000002978, 28.599996999997998, 1060.250027999999, 1752.3499849999946, 4913.499999, 3165.1499900000003, 2317.300020000005, 3140.950012999999, 8.499988999994713, 21.800005000000795, 756.9499829999966, 38.500012999994155, 2681.199993999997, 1324.7000059999964, 5.699994999998168, 1369.8999929999986, 25.800020000007763, 9.799983999999768, 1212.7999940000007, 37.70000399999719, 19.600018999999975, 22.600025000001324, 11.09996799999898]\n",
      "Total Portfolio value in episodes[13896.249998000003, 12642.199667, 12514.599346000003, 12592.200005, 12575.500299999998, 14304.799981000002, 13257.550034, 12552.200330000001, 12169.399990000002, 14482.199996000001, 13556.499988999998, 12232.900022000005, 13799.149988000003, 13839.099982999998, 12918.500310999996, 13893.000000000007, 14008.999986000003, 12251.800655000001, 13105.700004, 12181.599705999999, 14086.600004000004, 11774.899406999999, 12627.300334, 12805.799986999999, 13861.649989999998, 12272.199685999998, 12285.699372999998, 12386.399691000004, 12440.800610000004, 12155.099996999998, 14173.250027999999, 13935.349984999995, 13515.999999, 13906.64999, 14128.300020000006, 13789.450013, 12832.300307999994, 12283.399693000001, 14381.449982999997, 12643.300636999993, 14120.199993999997, 14065.700005999995, 12893.400640999998, 14622.399992999999, 12993.300670000008, 12625.099662999999, 14697.799994, 12519.200003999997, 12108.600019, 12456.399389000002, 12128.700615999998]\n",
      "------------------------------\n",
      "Total Days in episodes[599, 493, 344, 383, 381, 599, 584, 347, 536, 599, 599, 356, 599, 599, 469, 585, 599, 453, 599, 374, 599, 447, 396, 333, 599, 386, 490, 360, 467, 479, 599, 599, 599, 599, 599, 599, 403, 498, 599, 394, 599, 599, 470, 599, 378, 386, 599, 538, 536, 364, 453]\n",
      "Benchmark_Profit is  11607   with remaining Apple Stocks: 8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Apple stocks in episodes\"+ str(total_stock1bal))\n",
    "print(\"///////\")\n",
    "# print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "print(\"Total Open cash in episodes\"+ str(total_open_cash))\n",
    "print(\"Total Portfolio value in episodes\"+ str(total_port_value))\n",
    "print(\"------------------------------\")\n",
    "print(\"Total Days in episodes\"+ str(total_days_played))\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Total AoT stocks in episodes267\n",
      "///////\n",
      "Total Open cash in episodes2322.2999959999975\n",
      "Total Portfolio value in episodes12815.399728999997\n",
      "------------------------------\n",
      "Total Days in episodes499\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "pd_data1_test=pd_data1_test.reset_index(drop=True)\n",
    "data1_test=pd_data1_test['Close']\n",
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model_name='model_ep20.h5'\n",
    "\n",
    "model = load_model(\"models/\" + model_name)\n",
    "\n",
    "initial_cash = state_class_obj.portfolio_value\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]\n",
    "\n",
    "for e in range(1):\n",
    "    print(\"..........\")\n",
    "    \n",
    "    Bal_stock1 = int(np.floor((start_balance/2)/data1_train[0]))\n",
    "    open_cash=start_balance/2\n",
    "    datasize=test\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "#     agent = Agent(5)\n",
    "    agent = Agent(5, is_eval=True, model_name=model_name)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "        \n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "    \n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "#         print(\"State = get State ========\")\n",
    "#         print(state_array_obj)\n",
    "        action = agent.act(state_array_obj)\n",
    "#         print(\"Agent .get predict = \")\n",
    "#         print(agent.getPredict(state_array_obj))\n",
    "        print(action)           \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            print(action)\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "#                 reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            print(action)\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "#                 reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action\n",
    "            \n",
    "#                 if (abs(change_percent_stock1)<=2):\n",
    "# #                     reward=10000\n",
    "#                 elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "#                     reward=-1000000\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=1000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "            Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "            open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            #print(\"--------------------------------\")\n",
    "           # print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "           # print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "           # print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \n",
    "             #     \"  stock 1 number: \" + str(len(agent.inventory1))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "\n",
    "            print(\"Total AoT stocks in episodes\"+ str(Bal_stock1))\n",
    "            print(\"///////\")\n",
    "            # print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "            print(\"Total Open cash in episodes\"+ str(open_cash))\n",
    "            print(\"Total Portfolio value in episodes\"+ str(state_class_obj.portfolio_value))\n",
    "            print(\"------------------------------\")\n",
    "            print(\"Total Days in episodes\"+ str(t))\n",
    "\n",
    "#             print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))\n",
    "# #             if len(agent.memory) <= batch_size:\n",
    "#                 print(\"^_^\")\n",
    "#                 agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
