{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Agent\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
    "        self.state_size = state_size # normalized previous days\n",
    "        self.action_size = 3 #  buy_1, sell_1,DO Nothing\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.inventory1 = []\n",
    "        self.inventory2 = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        self.gamma = 0.95 #gamma is the discount factor. It quantifies how much importance we give for future rewards.\n",
    "        self.epsilon = 1.0 #Exploration and Exploitation — Epsilon (ε)\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = load_model(\"models/AOT/\" + model_name) if is_eval else self._model()\n",
    "\n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "#             print(\"random action\")\n",
    "            return random.randrange(self.action_size)\n",
    "#         print(\"Calculating using model\")\n",
    "#         print(self.model.predict(state))\n",
    "        options = self.model.predict(state)\n",
    "#         print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "    \n",
    "    def getPredict(self, state):\n",
    "        print(\"Predict using model\")\n",
    "        options = self.model.predict(state)\n",
    "        print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "\n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "#         print(\"expReplay\")\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "#             print(\"For loop\")\n",
    "            target = reward\n",
    "#             print(\"target = \"+str(target))\n",
    "#             print(\"Done = \"+str(done))\n",
    "            if not done:\n",
    "#                 print(\"Not Done\")\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "#             print(\"target_f\")\n",
    "#             print(target_f)\n",
    "#             print(target_f[0][action])\n",
    "            target_f[0][action] = target\n",
    "#             print(target_f)\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "#             print(\"Self model\")\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "#         print(\"Wtf model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockDataVec(key):\n",
    "    vec = []\n",
    "    lines = open(\"data/\" + key + \".txt\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vec.append(float(line.split(\",\")[4]))\n",
    "\n",
    "    return vec\n",
    "\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockVolVec(key):\n",
    "    vol = []\n",
    "    lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vol.append(float(line.split(\",\")[5]))\n",
    "\n",
    "    return vol\n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "import numpy as np\n",
    "import random\n",
    "import math, random \n",
    "import gym \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, data1, Bal_stock1, open_cash, timestep):\n",
    "        self.Stock1Price=data1[timestep] #stock 1 open price\n",
    "        self.Stock1Blnc=Bal_stock1 #stock 1 balance\n",
    "        self.open_cash=open_cash #cash balance\n",
    "        self.fiveday_stock1=self.five_day_window(data1, timestep)\n",
    "        #self.volume1=volume1[timestep]\n",
    "        #self.volume2=volume2[timestep]\n",
    "        self.portfolio_value=self.portfolio_value()\n",
    "\n",
    "    def portfolio_value(self):\n",
    "        pvalue=0\n",
    "        #print(\"In portfolio func\")\n",
    "        #print(\"self.Stock1Price\",self.Stock1Price, type(self.Stock1Price))\n",
    "        #print(\"self.Stock1Blnc\",self.Stock1Blnc[0], type(self.Stock1Blnc))\n",
    "\n",
    "        v1=self.Stock1Price * float(self.Stock1Blnc)\n",
    "        v2=float(self.open_cash)\n",
    "        return (v1+v2)\n",
    "    \n",
    "    def next_opening_price(self):\n",
    "        return data1[timestep+1]\n",
    "    \n",
    "    def five_day_window(self,data, timestep):\n",
    "        step = timestep\n",
    "        if step < 5:\n",
    "            return data[0]\n",
    "        \n",
    "        stock_5days = np.mean(data[step-5:step])\n",
    "        #print(\"stock_5days=\" + str(stock_5days))\n",
    "        #print(stock_5days)\n",
    "\n",
    "        #print(type(stock_5days))\n",
    "\n",
    "        return stock_5days\n",
    "    \n",
    "    def reset(self):\n",
    "        #self.state = torch.FloatTensor(torch.zeros(8)).cuda()\n",
    "        self.Stock1Price=151.25 #stock 1 open price Google\n",
    "#         self.Stock2Price=21.845 #stock 2 open price Walmart\n",
    "        self.Stock1Blnc=34 #stock 1 balance Google\n",
    "#         self.Stock2Blnc=221 #stock 2 balance Walmart\n",
    "        self.open_cash=10000 #cash balance\n",
    "        self.fiveday_stock1=151.25\n",
    "#         self.fiveday_stock2=21.845\n",
    "        self.portfolio_value=10000\n",
    "        \n",
    "    def getState(self):\n",
    "        #print(\"In get state\")\n",
    "        res=[]\n",
    "        res.append(self.Stock1Price) #stock 1 open price\n",
    "#         res.append(self.Stock2Price) #stock 2 open price\n",
    "        res.append(self.Stock1Blnc) #stock 1 balance\n",
    "#         res.append(self.Stock2Blnc) #stock 2 balance\n",
    "        res.append(self.open_cash) #cash balance\n",
    "        res.append(self.fiveday_stock1)\n",
    "#         res.append(self.fiveday_stock2)        \n",
    "        res.append(self.portfolio_value)\n",
    "        #res.append(self.volume1)\n",
    "        #res.append(self.volume2)\n",
    "\n",
    "\n",
    "        \n",
    "        #print(res)\n",
    "        res1=np.array([res])\n",
    "        #print(\"res array\"+np.array([res]))\n",
    "        return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math, random \n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#stock_name, window_size, episode_count = sys.argv[1], int(sys.argv[2]), int(sys.argv[3])\n",
    "\n",
    "stock_name1, episode_count, start_balance, training, test = 'AOT.BK', 50,10000,731,240\n",
    "\n",
    "\n",
    "pd_data1=pd.read_csv('data/'+stock_name1+'.csv', sep=\",\", header=0)\n",
    "# pd_data2=pd.read_csv('data/amzn.us.txt', sep=\",\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^\n"
     ]
    }
   ],
   "source": [
    "# if (pd_data1['Date'][0]>pd_data2['Date'][0]): \n",
    "#     #print(\"Date1 is older than Date2\")\n",
    "#     pd_data1=pd_data1[pd_data1.Date>=pd_data2['Date'][0]]\n",
    "#     pd_data1=pd_data1.reset_index(drop=True)\n",
    "# else:\n",
    "#     #print(\"Date2>Date1\")\n",
    "#     pd_data2=pd_data2[pd_data2.Date>=pd_data1['Date'][0]]\n",
    "#     pd_data2=pd_data2.reset_index(drop=True)\n",
    "    #print(\"Date2>Date1  and date2 is\" + str(pd_data2['Date'][0]) +\" Date 1 is : \"+ str(pd_data1['Date'][0]))\n",
    "print(\"^^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre -Processing the Datasheet ...Drop Data that is not in both stock data- some days data is missing in Apple and some in Amazon\n",
    "import datetime\n",
    "#timestamp = data1_date[10]\n",
    "#print(timestamp.strftime('%Y-%m-%d'))\n",
    "#Convert  Date to Date format\n",
    "pd_data1['Date']=pd.to_datetime(pd_data1['Date'], format='%Y/%m/%d')\n",
    "# pd_data2['Date']=pd.to_datetime(pd_data2['Date'], format='%Y/%m/%d')\n",
    "\n",
    "list1= pd_data1['Date']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "pd_data1_train=pd_data1[0:training]\n",
    "# pd_data2_train=pd_data2[0:training]\n",
    "#Test Data\n",
    "pd_data1_test=pd_data1[training:training+test]\n",
    "# pd_data2_test=pd_data2[training:training+test]\n",
    "pd_data1_test=pd_data1_test.reset_index(drop=True) \n",
    "\n",
    "\n",
    "vol1_train=getStockVolVec(stock_name1)\n",
    "# vol2_train=getStockVolVec(stock_name2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Stock AOT.BK = 17.0 unit\n",
      "Benchmark_Profit is  10435.5with Apple Stocks:  8.0\n"
     ]
    }
   ],
   "source": [
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "\n",
    "# total_Prof=[]\n",
    "# done=False\n",
    "\n",
    "#Benchmark Model\n",
    "#In this model, we would divide \n",
    "\n",
    "\n",
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "#print(df_data1)\n",
    "total_Prof=[]\n",
    "done=False\n",
    "\n",
    "Act_datasize = test\n",
    "batch_size = 64\n",
    "\n",
    "#Benchmark Model\n",
    "\n",
    "data1_test=pd_data1_test['Open']\n",
    "data1_train=pd_data1_train['Open']\n",
    "\n",
    "data1_date=pd_data1_train['Date']\n",
    "data1_test=pd_data1_test['Date']\n",
    "\n",
    "# Start with half of money bought stock1\n",
    "Act_Bench_Stock1_Bal=int(np.floor((start_balance/2)/data1_train[0]))\n",
    "# Act_Bench_Stock2_Bal=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "Act_Bench_Open_cash=start_balance/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Program to calculate benchmark profit\n",
    "\n",
    "\n",
    "#sell 10% of stock in 10 intervals\n",
    "#Example 100 days of data set.Sold every 10 days of 10%.\n",
    "\n",
    "interval=int(Act_datasize/10)\n",
    "Total_Stock1_Amount= Act_Bench_Stock1_Bal\n",
    "# Total_Stock2_Amount= 0\n",
    "stocks2Value = 0\n",
    "# stocks1Value = 0\n",
    "\n",
    "Act_stocks1=np.floor(Act_Bench_Stock1_Bal /10)\n",
    "# Act_stocks2=np.floor(Act_Bench_Stock2_Bal /10)\n",
    "print(\"Buy Stock \"+stock_name1+\" = \"+str(Act_stocks1)+\" unit\")\n",
    "# print(str(Act_stocks2))\n",
    "\n",
    "remaining_stock1=Act_Bench_Stock1_Bal\n",
    "# remaining_stock2=Act_Bench_Stock2_Bal\n",
    "ttl=0\n",
    "\n",
    "Benchmark_Port_Value=[]\n",
    "\n",
    "\n",
    "for j in range (interval,Act_datasize+1,interval):\n",
    "        #print(\"closing prices : \" + str(data1_train[j-1]) )\n",
    "        Price_closing_Stock1=data1_train[j-1]\n",
    "#         Price_closing_Stock2=data2_train[j-1]\n",
    "        \n",
    "        date_stock1=data1_date[j-1].strftime('%Y-%m-%d')\n",
    "        #print(date_stock1)\n",
    "                \n",
    "        stocks1Value= Act_stocks1 * Price_closing_Stock1\n",
    "#         stocks2Value= Act_stocks2 * Price_closing_Stock2\n",
    "        remaining_stock1=remaining_stock1-Act_stocks1\n",
    "#         remaining_stock2=remaining_stock2-Act_stocks2\n",
    "        #print(\"J is:\"+ str(j))\n",
    "        \n",
    "        \n",
    "        \n",
    "        Stock1_Port_value=remaining_stock1*Price_closing_Stock1\n",
    "#         Stock2_Port_value=remaining_stock2*Price_closing_Stock2\n",
    "        Act_Bench_Open_cash=Act_Bench_Open_cash+stocks1Value+stocks2Value #Adding 10% sold value into open cash\n",
    "        \n",
    "        Total_Portfolio_value=Act_Bench_Open_cash+Stock1_Port_value\n",
    "        Benchmark_Port_Value.append([date_stock1,Total_Portfolio_value])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#print (\"total_Test_Benchmark_amount : \" +  str(Total_Portfolio_value))\n",
    "\n",
    "Training_Benchmark_Portfolio_Value= Total_Portfolio_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(Training_Benchmark_Portfolio_Value) +\"with Apple Stocks:  \" + str(remaining_stock1))\n",
    "\n",
    "\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialize Agent\n",
    "# agent = Agent(5)\n",
    "# Bal_stock1=int(0)\n",
    "# open_cash=start_balance\n",
    "    \n",
    "# datasize=training\n",
    "# reward = 0\n",
    "# state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# state_array_obj=state_class_obj.getState()\n",
    "# action = agent.act(state_array_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Initialize Agent\n",
    "# # agent = Agent(5)\n",
    "# # Bal_stock1=int(0)\n",
    "# # open_cash=start_balance\n",
    "    \n",
    "# # datasize=training\n",
    "# # reward = 0\n",
    "# # state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# # state_array_obj=state_class_obj.getState()\n",
    "# # action = agent.act(state_array_obj)\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))\n",
    "# print(\"Action =\"+ str(action))\n",
    "# print(agent.getPredict(state_array_obj))\n",
    "# next_state_class_obj=State(data1_train, Bal_stock1, open_cash,1)\n",
    "# next_state_array_obj=next_state_class_obj.getState()\n",
    "# print(\"..........\")   \n",
    "# #                          state, action, reward, next_state, done\n",
    "# agent.memory.append((state_array_obj, 1, -500000, next_state_array_obj, True))\n",
    "# # agent.expReplay(len(agent.memory))\n",
    "# print(agent.getPredict(next_state_array_obj))\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0908 21:01:41.743113 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0908 21:01:41.757681 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0908 21:01:41.759691 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0908 21:01:41.834639 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0908 21:01:41.874917 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0908 21:01:41.876322 4650329536 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 0/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 16196.900002  stock 1 number: 128\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 1/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 15610.599992  stock 1 number: 107\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 2/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 15631.799998999999  stock 1 number: 115\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 3/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 15540.599994  stock 1 number: 112\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 4/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 16202.500015000001  stock 1 number: 126\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 5/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 17419.050013000004  stock 1 number: 182\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 6/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 16935.250002  stock 1 number: 168\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 7/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 16014.800004  stock 1 number: 130\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 8/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 16231.149985999999  stock 1 number: 131\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 9/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 17102.900003  stock 1 number: 173\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 10/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 17632.600015999997  stock 1 number: 192\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 11/50\n",
      "--------------------------------\n",
      "Total Profit: $0.00\n",
      "Total No. of days played: 730  out of overall days:  731\n",
      "Total portfolio value: 14868.699996000001  stock 1 number: 81\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 12/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4b7651eecb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpReplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-1b829f79f38a>\u001b[0m in \u001b[0;36mexpReplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#                 print(\"Not Done\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#             print(\"target_f\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#             print(target_f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"..........\")\n",
    "    print(\"Episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    \n",
    "#     Bal_stock1=int(0)\n",
    "    Bal_stock1 = int(np.floor((start_balance/2)/data1_train[0]))\n",
    "#     Bal_stock2=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "    open_cash=start_balance/2\n",
    "    datasize=training\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "    agent = Agent(5)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "#     agent.inventory2 =[]\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "#     for i in range(Bal_stock2):\n",
    "#         agent.inventory2.append(data2_train[0]) \n",
    "    \n",
    "    \n",
    "    #Timestep delta to make sure that with time reward increases for taking action\n",
    "    #timestep_delta=0\n",
    "    \n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "        action = agent.act(state_array_obj)\n",
    "                   \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "                reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "                #needs to be reviewed\n",
    "                if(state_class_obj.open_cash<500):\n",
    "                    reward=-1000\n",
    "                elif (state_class_obj.Stock1Price > state_class_obj.fiveday_stock1):\n",
    "                    reward=abs(state_class_obj.Stock1Price - state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "                    if(Bal_stock1_t1 == 1):\n",
    "                        reward = 30000\n",
    "                else:  \n",
    "                    reward=-abs(change_percent_stock1)*100\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:  \n",
    "#                     reward=-change_percent_stock1*100\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "                reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "          \n",
    "                if(state_class_obj.Stock1Blnc<10):\n",
    "                    reward=-100000\n",
    "                elif (abs(change_percent_stock1)<=1):\n",
    "                    reward=-abs(change_percent_stock1)*100\n",
    "                else:\n",
    "                    reward=change_percent_stock1*100 #State[0] is the price of stock 1. Here we are buying 1 stock\n",
    "                \n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action    \n",
    "                if (abs(change_percent_stock1)<=2):\n",
    "                    reward=100\n",
    "                elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "                    reward=-1000000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "                \n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "            print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "            print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \"  stock 1 number: \" + str(len(agent.inventory1)))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "            total_Prof.append(total_profit)\n",
    "            total_stock1bal.append(len(agent.inventory1))\n",
    "#             total_stock2bal.append(len(agent.inventory2))\n",
    "            total_open_cash.append(state_class_obj.open_cash)\n",
    "            total_port_value.append(state_class_obj.portfolio_value)\n",
    "            total_days_played.append(t)\n",
    "            if len(agent.memory) <= batch_size:\n",
    "                print(\"^_^\")\n",
    "                agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)\n",
    "\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        agent.model.save(\"models/model_ep\" + str(e)+\".h5\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Apple stocks in episodes\"+ str(total_stock1bal))\n",
    "print(\"///////\")\n",
    "# print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "print(\"Total Open cash in episodes\"+ str(total_open_cash))\n",
    "print(\"Total Portfolio value in episodes\"+ str(total_port_value))\n",
    "print(\"------------------------------\")\n",
    "print(\"Total Days in episodes\"+ str(total_days_played))\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open   High    Low  Close  Adj Close     Volume\n",
      "0 2018-01-04  71.25  71.25  70.00  70.50  69.352325   37773200\n",
      "1 2018-01-05  70.75  72.25  70.50  72.00  70.827911   48929600\n",
      "2 2018-01-08  72.75  77.75  72.50  74.25  73.041283  127056900\n",
      "3 2018-01-09  74.00  74.00  72.25  73.25  72.057564   89764400\n",
      "4 2018-01-10  72.75  73.00  71.00  71.25  70.090118  101608200\n",
      "          Date   Open   High    Low  Close  Adj Close    Volume\n",
      "235 2018-12-18  63.00  63.50  62.00  62.75      62.75  28948300\n",
      "236 2018-12-19  62.75  64.00  62.25  63.75      63.75  22566400\n",
      "237 2018-12-20  63.25  64.50  63.25  64.50      64.50  15332500\n",
      "238 2018-12-21  63.75  65.25  63.75  64.50      64.50  23184100\n",
      "239 2018-12-24  64.25  65.75  64.25  65.00      65.00  23454000\n",
      "..........\n",
      "240\n",
      "731\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Total AoT stocks in episodes418\n",
      "///////\n",
      "Total Open cash in episodes2839.800004\n",
      "Total Portfolio value in episodes17260.800004\n",
      "------------------------------\n",
      "Total Days in episodes239\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "pd_data1_test=pd_data1_test.reset_index(drop=True)\n",
    "data1_test=pd_data1_test['Open']\n",
    "print(pd_data1_test.head())\n",
    "print(pd_data1_test.tail())\n",
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model_name='model_ep50.h5'\n",
    "\n",
    "initial_cash = state_class_obj.portfolio_value\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]\n",
    "\n",
    "for e in range(1):\n",
    "    print(\"..........\")\n",
    "#     Bal_stock1 = 0\n",
    "    Bal_stock1 = int(np.floor((start_balance/2)/data1_train[0]))\n",
    "    open_cash=start_balance\n",
    "    datasize=test\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "#     agent = Agent(5)\n",
    "    agent = Agent(5, is_eval=True, model_name=model_name)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "        \n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "    print(datasize)\n",
    "    print(len(data1_train))\n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "#         print(\"State = get State ========\")\n",
    "#         print(state_array_obj)\n",
    "        action = agent.act(state_array_obj)\n",
    "#         print(\"Agent .get predict = \")\n",
    "#         print(agent.getPredict(state_array_obj))\n",
    "        print(action)           \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            print(action)\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "#                 reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            print(action)\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "#                 reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action\n",
    "            if (abs(change_percent_stock1)<=2):\n",
    "                reward=abs(change_percent_stock1)*100\n",
    "#                 elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "#                     reward=-1000000\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=1000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "            Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "#             open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            #print(\"--------------------------------\")\n",
    "           # print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "           # print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "           # print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \n",
    "             #     \"  stock 1 number: \" + str(len(agent.inventory1))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "\n",
    "            print(\"Total AoT stocks in episodes\"+ str(Bal_stock1))\n",
    "            print(\"///////\")\n",
    "            # print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "            print(\"Total Open cash in episodes\"+ str(open_cash))\n",
    "            print(\"Total Portfolio value in episodes\"+ str(state_class_obj.portfolio_value))\n",
    "            print(\"------------------------------\")\n",
    "            print(\"Total Days in episodes\"+ str(t))\n",
    "\n",
    "#             print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))\n",
    "# #             if len(agent.memory) <= batch_size:\n",
    "#                 print(\"^_^\")\n",
    "#                 agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
