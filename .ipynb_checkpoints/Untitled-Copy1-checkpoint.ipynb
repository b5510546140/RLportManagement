{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
    "        self.state_size = state_size # normalized previous days\n",
    "        self.action_size = 3 #  buy_1, sell_1,DO Nothing\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.inventory1 = []\n",
    "        self.inventory2 = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        self.gamma = 0.95 #gamma is the discount factor. It quantifies how much importance we give for future rewards.\n",
    "        self.epsilon = 1.0 #Exploration and Exploitation — Epsilon (ε)\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = load_model(\"models/\" + model_name) if is_eval else self._model()\n",
    "\n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.0001))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "#             print(\"random action\")\n",
    "            return random.randrange(self.action_size)\n",
    "#         print(\"Calculating using model\")\n",
    "        print(self.model.predict(state))\n",
    "        options = self.model.predict(state)\n",
    "#         print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "    \n",
    "    def getPredict(self, state):\n",
    "        print(\"Predict using model\")\n",
    "        options = self.model.predict(state)\n",
    "        print(str(options))\n",
    "        return np.argmax(options[0])\n",
    "\n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "#         print(\"expReplay\")\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "#             print(\"For loop\")\n",
    "            target = reward\n",
    "#             print(\"target = \"+str(target))\n",
    "#             print(\"Done = \"+str(done))\n",
    "            if not done:\n",
    "#                 print(\"Not Done\")\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "#             print(\"target_f\")\n",
    "#             print(target_f)\n",
    "#             print(target_f[0][action])\n",
    "            target_f[0][action] = target\n",
    "#             print(target_f)\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "#             print(\"Self model\")\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "#         print(\"Wtf model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockDataVec(key):\n",
    "    vec = []\n",
    "    lines = open(\"data/\" + key + \".txt\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vec.append(float(line.split(\",\")[4]))\n",
    "\n",
    "    return vec\n",
    "\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockVolVec(key):\n",
    "    vol = []\n",
    "    lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        vol.append(float(line.split(\",\")[5]))\n",
    "\n",
    "    return vol\n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "import numpy as np\n",
    "import random\n",
    "import math, random \n",
    "import gym \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "class State:\n",
    "    def __init__(self, data1, Bal_stock1, open_cash, timestep):\n",
    "        self.Stock1Price=data1[timestep] #stock 1 open price\n",
    "        self.Stock1Blnc=Bal_stock1 #stock 1 balance\n",
    "        self.open_cash=open_cash #cash balance\n",
    "        self.fiveday_stock1=self.five_day_window(data1, timestep)\n",
    "        #self.volume1=volume1[timestep]\n",
    "        #self.volume2=volume2[timestep]\n",
    "        self.portfolio_value=self.portfolio_value()\n",
    "\n",
    "    def portfolio_value(self):\n",
    "        pvalue=0\n",
    "        #print(\"In portfolio func\")\n",
    "        #print(\"self.Stock1Price\",self.Stock1Price, type(self.Stock1Price))\n",
    "        #print(\"self.Stock1Blnc\",self.Stock1Blnc[0], type(self.Stock1Blnc))\n",
    "\n",
    "        v1=self.Stock1Price * float(self.Stock1Blnc)\n",
    "        v2=float(self.open_cash)\n",
    "        return (v1+v2)\n",
    "    \n",
    "    def next_opening_price(self):\n",
    "        return data1[timestep+1]\n",
    "    \n",
    "    def five_day_window(self,data, timestep):\n",
    "        step = timestep\n",
    "        if step < 5:\n",
    "            return data[0]\n",
    "        \n",
    "        stock_5days = np.mean(data[step-5:step])\n",
    "        #print(\"stock_5days=\" + str(stock_5days))\n",
    "        #print(stock_5days)\n",
    "\n",
    "        #print(type(stock_5days))\n",
    "\n",
    "        return stock_5days\n",
    "    \n",
    "    def reset(self):\n",
    "        #self.state = torch.FloatTensor(torch.zeros(8)).cuda()\n",
    "        self.Stock1Price=151.25 #stock 1 open price Google\n",
    "#         self.Stock2Price=21.845 #stock 2 open price Walmart\n",
    "        self.Stock1Blnc=34 #stock 1 balance Google\n",
    "#         self.Stock2Blnc=221 #stock 2 balance Walmart\n",
    "        self.open_cash=10000 #cash balance\n",
    "        self.fiveday_stock1=151.25\n",
    "#         self.fiveday_stock2=21.845\n",
    "        self.portfolio_value=10000\n",
    "        \n",
    "    def getState(self):\n",
    "        #print(\"In get state\")\n",
    "        res=[]\n",
    "        res.append(self.Stock1Price) #stock 1 open price\n",
    "#         res.append(self.Stock2Price) #stock 2 open price\n",
    "        res.append(self.Stock1Blnc) #stock 1 balance\n",
    "#         res.append(self.Stock2Blnc) #stock 2 balance\n",
    "        res.append(self.open_cash) #cash balance\n",
    "        res.append(self.fiveday_stock1)\n",
    "#         res.append(self.fiveday_stock2)        \n",
    "        res.append(self.portfolio_value)\n",
    "        #res.append(self.volume1)\n",
    "        #res.append(self.volume2)\n",
    "\n",
    "\n",
    "        \n",
    "        #print(res)\n",
    "        res1=np.array([res])\n",
    "        #print(\"res array\"+np.array([res]))\n",
    "        return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math, random \n",
    "import numpy as np \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#stock_name, window_size, episode_count = sys.argv[1], int(sys.argv[2]), int(sys.argv[3])\n",
    "\n",
    "stock_name1, episode_count, start_balance, training, test = 'AOT.BK', 100,10000,731,100\n",
    "\n",
    "\n",
    "pd_data1=pd.read_csv('data/AOT.BK.csv', sep=\",\", header=0)\n",
    "# pd_data2=pd.read_csv('data/amzn.us.txt', sep=\",\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^\n"
     ]
    }
   ],
   "source": [
    "# if (pd_data1['Date'][0]>pd_data2['Date'][0]): \n",
    "#     #print(\"Date1 is older than Date2\")\n",
    "#     pd_data1=pd_data1[pd_data1.Date>=pd_data2['Date'][0]]\n",
    "#     pd_data1=pd_data1.reset_index(drop=True)\n",
    "# else:\n",
    "#     #print(\"Date2>Date1\")\n",
    "#     pd_data2=pd_data2[pd_data2.Date>=pd_data1['Date'][0]]\n",
    "#     pd_data2=pd_data2.reset_index(drop=True)\n",
    "    #print(\"Date2>Date1  and date2 is\" + str(pd_data2['Date'][0]) +\" Date 1 is : \"+ str(pd_data1['Date'][0]))\n",
    "print(\"^^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre -Processing the Datasheet ...Drop Data that is not in both stock data- some days data is missing in Apple and some in Amazon\n",
    "import datetime\n",
    "#timestamp = data1_date[10]\n",
    "#print(timestamp.strftime('%Y-%m-%d'))\n",
    "#Convert  Date to Date format\n",
    "pd_data1['Date']=pd.to_datetime(pd_data1['Date'], format='%Y/%m/%d')\n",
    "# pd_data2['Date']=pd.to_datetime(pd_data2['Date'], format='%Y/%m/%d')\n",
    "\n",
    "list1= pd_data1['Date']\n",
    "# list2= pd_data2['Date']\n",
    "# diff_pd1_data = list(set(list1) - set(list2))\n",
    "# diff_pd2_data = list(set(list2) - set(list1))\n",
    "#x11=x[0].strftime('%Y-%m-%d 00:00:00')\n",
    "#p=datetime.datetime.strptime(x11, \"%Y-%m-%d 00:00:00\")\n",
    "#print(p)\n",
    "# for k in range(len(diff_pd1_data)):\n",
    "#     pd1_dat_format=diff_pd1_data[k].strftime('%Y-%m-%d 00:00:00')\n",
    "#     date_format_pd1=datetime.datetime.strptime(pd1_dat_format, \"%Y-%m-%d 00:00:00\")\n",
    "#     for i, j in enumerate(list1):\n",
    "#         if j == date_format_pd1:\n",
    "#             #print(i)\n",
    "#             pd_data1=pd_data1.drop([i])            \n",
    "# pd_data1=pd_data1.reset_index(drop=True)\n",
    "\n",
    "# for k in range(len(diff_pd2_data)):\n",
    "#     pd2_dat_format=diff_pd2_data[k].strftime('%Y-%m-%d 00:00:00')\n",
    "#     date_format_pd2=datetime.datetime.strptime(pd2_dat_format, \"%Y-%m-%d 00:00:00\")\n",
    "#     for M, N in enumerate(list2):\n",
    "#         if N == date_format_pd2:\n",
    "#             #print(M)\n",
    "#             pd_data2=pd_data2.drop([M])\n",
    "            \n",
    "# pd_data2=pd_data2.reset_index(drop=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "pd_data1_train=pd_data1[0:training]\n",
    "# pd_data2_train=pd_data2[0:training]\n",
    "#Test Data\n",
    "pd_data1_test=pd_data1[training:training+test]\n",
    "# pd_data2_test=pd_data2[training:training+test]\n",
    "\n",
    "\n",
    "\n",
    "vol1_train=getStockVolVec(stock_name1)\n",
    "# vol2_train=getStockVolVec(stock_name2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Stock AOT.BK = 17.0 unit\n",
      "Benchmark_Profit is  12640.599898with Apple Stocks:  8.0\n"
     ]
    }
   ],
   "source": [
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "\n",
    "# total_Prof=[]\n",
    "# done=False\n",
    "\n",
    "#Benchmark Model\n",
    "#In this model, we would divide \n",
    "\n",
    "\n",
    "#Initialize state and set benchmarking model\n",
    "\n",
    "\n",
    "#print(df_data1)\n",
    "total_Prof=[]\n",
    "done=False\n",
    "\n",
    "Act_datasize = training\n",
    "batch_size = 64\n",
    "\n",
    "#Benchmark Model\n",
    "\n",
    "data1_train=pd_data1_train['Open']\n",
    "# data2_train=pd_data2_train['Open']\n",
    "\n",
    "data1_date=pd_data1_train['Date']\n",
    "# Start with half of money bought stock1\n",
    "Act_Bench_Stock1_Bal=int(np.floor((start_balance/2)/data1_train[0]))\n",
    "# Act_Bench_Stock2_Bal=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "Act_Bench_Open_cash=start_balance/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Program to calculate benchmark profit\n",
    "\n",
    "\n",
    "#sell 10% of stock in 10 intervals\n",
    "#Example 100 days of data set.Sold every 10 days of 10%.\n",
    "\n",
    "interval=int(Act_datasize/10)\n",
    "Total_Stock1_Amount= 0\n",
    "# Total_Stock2_Amount= 0\n",
    "stocks2Value = 0\n",
    "# stocks1Value = 0\n",
    "\n",
    "Act_stocks1=np.floor(Act_Bench_Stock1_Bal /10)\n",
    "# Act_stocks2=np.floor(Act_Bench_Stock2_Bal /10)\n",
    "print(\"Buy Stock \"+stock_name1+\" = \"+str(Act_stocks1)+\" unit\")\n",
    "# print(str(Act_stocks2))\n",
    "\n",
    "remaining_stock1=Act_Bench_Stock1_Bal\n",
    "# remaining_stock2=Act_Bench_Stock2_Bal\n",
    "ttl=0\n",
    "\n",
    "Benchmark_Port_Value=[]\n",
    "\n",
    "\n",
    "for j in range (interval,Act_datasize+1,interval):\n",
    "        #print(\"closing prices : \" + str(data1_train[j-1]) )\n",
    "        Price_closing_Stock1=data1_train[j-1]\n",
    "#         Price_closing_Stock2=data2_train[j-1]\n",
    "        \n",
    "        date_stock1=data1_date[j-1].strftime('%Y-%m-%d')\n",
    "        #print(date_stock1)\n",
    "                \n",
    "        stocks1Value= Act_stocks1 * Price_closing_Stock1\n",
    "#         stocks2Value= Act_stocks2 * Price_closing_Stock2\n",
    "        remaining_stock1=remaining_stock1-Act_stocks1\n",
    "#         remaining_stock2=remaining_stock2-Act_stocks2\n",
    "        #print(\"J is:\"+ str(j))\n",
    "        \n",
    "        \n",
    "        \n",
    "        Stock1_Port_value=remaining_stock1*Price_closing_Stock1\n",
    "#         Stock2_Port_value=remaining_stock2*Price_closing_Stock2\n",
    "        Act_Bench_Open_cash=Act_Bench_Open_cash+stocks1Value+stocks2Value #Adding 10% sold value into open cash\n",
    "        \n",
    "        Total_Portfolio_value=Act_Bench_Open_cash+Stock1_Port_value\n",
    "        Benchmark_Port_Value.append([date_stock1,Total_Portfolio_value])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#print (\"total_Test_Benchmark_amount : \" +  str(Total_Portfolio_value))\n",
    "\n",
    "Training_Benchmark_Portfolio_Value= Total_Portfolio_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(Training_Benchmark_Portfolio_Value) +\"with Apple Stocks:  \" + str(remaining_stock1))\n",
    "\n",
    "\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 19:14:22.149538 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0901 19:14:22.162090 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0901 19:14:22.164623 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0901 19:14:22.220829 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #Initialize Agent\n",
    "# agent = Agent(5)\n",
    "# Bal_stock1=int(0)\n",
    "# open_cash=start_balance\n",
    "    \n",
    "# datasize=training\n",
    "# reward = 0\n",
    "# state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# state_array_obj=state_class_obj.getState()\n",
    "# action = agent.act(state_array_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 19:14:22.238878 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0901 19:14:22.240993 4429239744 deprecation_wrapper.py:119] From /Users/watwattanagaroon/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent memory = 0\n",
      "Action =2\n",
      "Predict using model\n",
      "[[ -504.17358 -1849.4805   1784.0701 ]]\n",
      "2\n",
      "..........\n",
      "Predict using model\n",
      "[[ -504.18762 -1849.519    1784.1592 ]]\n",
      "2\n",
      "Agent memory = 1\n"
     ]
    }
   ],
   "source": [
    "# # #Initialize Agent\n",
    "# # agent = Agent(5)\n",
    "# # Bal_stock1=int(0)\n",
    "# # open_cash=start_balance\n",
    "    \n",
    "# # datasize=training\n",
    "# # reward = 0\n",
    "# # state_class_obj= State(data1_train, Bal_stock1, open_cash,0)\n",
    "# # state_array_obj=state_class_obj.getState()\n",
    "# # action = agent.act(state_array_obj)\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))\n",
    "# print(\"Action =\"+ str(action))\n",
    "# print(agent.getPredict(state_array_obj))\n",
    "# next_state_class_obj=State(data1_train, Bal_stock1, open_cash,1)\n",
    "# next_state_array_obj=next_state_class_obj.getState()\n",
    "# print(\"..........\")   \n",
    "# #                          state, action, reward, next_state, done\n",
    "# agent.memory.append((state_array_obj, 1, -500000, next_state_array_obj, True))\n",
    "# # agent.expReplay(len(agent.memory))\n",
    "# print(agent.getPredict(next_state_array_obj))\n",
    "# print(\"Agent memory = \"+ str(len(agent.memory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "Episode 0/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 1/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 2/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 3/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 4/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 5/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 6/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 7/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 8/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 9/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 10/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 11/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 12/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 13/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 14/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 15/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 16/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 17/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 18/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 19/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 20/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 21/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 22/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 23/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 24/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 25/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 26/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 27/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 28/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 29/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 30/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 31/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 32/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 33/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 34/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 35/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 36/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 37/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 38/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 39/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 40/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 41/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 42/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 43/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 44/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 45/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 46/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 47/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 48/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 49/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 50/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 51/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 52/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 53/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 54/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 55/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 56/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 57/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 58/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 59/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 60/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 61/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 62/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 63/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 64/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 65/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 66/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 67/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 68/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 69/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 70/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 71/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 72/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 73/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 74/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 75/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 76/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 77/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 78/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 79/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 80/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 81/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 82/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 83/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 84/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 85/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 86/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 87/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 88/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 89/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 90/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 91/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 92/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 93/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 94/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 95/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 96/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 97/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 98/100\n",
      "^_^\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 99/100\n",
      "--------------------------------\n",
      "..........\n",
      "Episode 100/100\n",
      "^_^\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"..........\")\n",
    "    print(\"Episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    \n",
    "    Bal_stock1=int(0)\n",
    "#     Bal_stock1 = int(np.floor((start_balance/2)/data1_train[0]))\n",
    "#     Bal_stock2=int(np.floor((start_balance/4)/data2_train[0]))\n",
    "    open_cash=start_balance\n",
    "    datasize=training\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "    agent = Agent(5)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "#     agent.inventory2 =[]\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "#     for i in range(Bal_stock2):\n",
    "#         agent.inventory2.append(data2_train[0]) \n",
    "    \n",
    "    \n",
    "    #Timestep delta to make sure that with time reward increases for taking action\n",
    "    #timestep_delta=0\n",
    "    \n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "        action = agent.act(state_array_obj)\n",
    "                   \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "                reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "                #needs to be reviewed\n",
    "                if(Bal_stock1_t1 == 0):\n",
    "                    reward = 300000\n",
    "                elif(state_class_obj.open_cash<500):\n",
    "                    reward=-100000\n",
    "                elif (state_class_obj.Stock1Price > state_class_obj.fiveday_stock1):\n",
    "                    reward+=1000\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:  \n",
    "#                     reward=-change_percent_stock1*100\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "                reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "          \n",
    "                if(state_class_obj.Stock1Blnc<10):\n",
    "                    reward=-100000\n",
    "                elif (abs(change_percent_stock1)<=2):\n",
    "                    reward=-10000\n",
    "                else:\n",
    "                    reward=change_percent_stock1*100 #State[0] is the price of stock 1. Here we are buying 1 stock\n",
    "                \n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action    \n",
    "                if (abs(change_percent_stock1)<=2):\n",
    "                    reward=10000\n",
    "                elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "                    reward=-1000000\n",
    "                elif (abs(change_percent_stock1)<=2):\n",
    "                    reward=1000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "                \n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "        \n",
    "        \n",
    "#         if action == 3:  #buy stock 2\n",
    "#             if state_class_obj.Stock2Price > state_class_obj.open_cash:\n",
    "#                 '''\n",
    "#                 print(\"Buy stock 2 when it did not have cash, so bankrupt, end of episode\")\n",
    "#                 reward=-reward_timedelta*10\n",
    "#                 done = True\n",
    "                \n",
    "#                 '''\n",
    "#                 #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "#                 #it should pick from other actions\n",
    "#                 #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "#                  #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "#                 #else:    \n",
    "#                 #print(\"Bankrupt\")\n",
    "#                 reward=-200000\n",
    "#                 done = True\n",
    "#                      #end episode   \n",
    "#             else:\n",
    "#                 #print(\"In Buy stock 2\")\n",
    "#                 agent.inventory2.append(data2_train[t])\n",
    "#                 Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "#                 open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock2Price\n",
    "                \n",
    "#                 if(state_class_obj.open_cash<5000):\n",
    "#                     reward=-100000\n",
    "#                 elif (abs(change_percent_stock2)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:\n",
    "#                     reward=-change_percent_stock2*100\n",
    " \n",
    "        \n",
    "#         if action == 4:  #sell stock 2\n",
    "#             if state_class_obj.Stock2Blnc <1 :\n",
    "#                     #print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "#                     reward=-200000\n",
    "#                     done = True\n",
    "#                 #end episode\n",
    "#             else:\n",
    "#                 #print(\"In sell stock 2\")\n",
    "#                 bought_price2=agent.inventory2.pop(0)\n",
    "#                 Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "#                 open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock2Price\n",
    "    \n",
    "              \n",
    "#                 if(state_class_obj.Stock2Blnc<10):\n",
    "#                     reward=-100000\n",
    "#                 elif (abs(change_percent_stock2)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:\n",
    "#                     reward=change_percent_stock2*100 \n",
    "                \n",
    "                \n",
    "#                 total_profit += state_class_obj.Stock2Price - bought_price2\n",
    "\n",
    "#                # print(\"reward for selling stock2: \" + str(reward))\n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            #print(\"--------------------------------\")\n",
    "           # print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "           # print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "           # print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \n",
    "             #     \"  stock 1 number: \" + str(len(agent.inventory1))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "\n",
    "            total_Prof.append(total_profit)\n",
    "            total_stock1bal.append(len(agent.inventory1))\n",
    "#             total_stock2bal.append(len(agent.inventory2))\n",
    "            total_open_cash.append(state_class_obj.open_cash)\n",
    "            total_port_value.append(state_class_obj.portfolio_value)\n",
    "            total_days_played.append(t)\n",
    "            if len(agent.memory) <= batch_size:\n",
    "                print(\"^_^\")\n",
    "                agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)\n",
    "\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        agent.model.save(\"models/model_ep\" + str(e))\n",
    "        \n",
    "\n",
    "        \n",
    "#print(\"Total Apple stocks in episodes\"+ str(total_stock1bal))\n",
    "#print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "#print(\"Total Open cash in episodes\"+ str(total_open_cash))\n",
    "#print(\"Total Portfolio value in episodes\"+ str(total_port_value))\n",
    "#print(\"Total Days in episodes\"+ str(total_days_played))\n",
    "#print(\"Benchmark_Profit is  \" + str(int(Benchmark_Portfolio_Value)) +\"   with Apple Stocks: \" + str(Bench_Stock1_Bal) + \n",
    "    #  \"   and Amazon stocks: \"+ str(Bench_Stock2_Bal) )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Apple stocks in episodes[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 10, 0, 0, 0]\n",
      "///////\n",
      "Total Open cash in episodes[9999.9, 10000, 10000, 10000, 10003.500002999997, 10000.199999999999, 9994.300001000001, 9998.9, 10002.700003999997, 10000, 9998.9, 10000.3, 10005.300003999995, 9987.600006999995, 10000, 9998.9, 9259.350011999994, 10000, 10000, 10004.100002, 10000, 8704.00000899999, 10000, 10000, 10000.300006999994, 10000, 10000, 10000, 10000, 10000.9, 9996.599998999998, 10000, 9998.9, 10001.4, 10001.5, 10000.6, 10000.700004999997, 10000, 10006.300003, 10000, 10000, 10000, 9999.700002, 9999.9, 10004.4, 10000, 10005.2, 9998.9, 10000, 10000, 10000, 10002.2, 10000, 9606.450003999997, 10000.9, 10000, 10000, 10011.999998000001, 10000, 10000, 10000.900001, 10000, 10000, 10000, 10000, 9594.150006000002, 10000, 10007.899998000003, 10000, 10000, 10000.199996000003, 10003.5, 10016.999999, 9541.700006999992, 10004.299997000002, 10000, 10001.700003999998, 10000, 10000.099999, 9999.299999, 9700.750003999989, 10000, 10000, 10010.5, 9998.9, 10001.599999000002, 10000, 9999.600000999999, 10001.4, 10000, 10000, 9998.9, 10000, 10004.899999000003, 10000, 9991.300017999985, 9831.400000000005, 9845.550034999995, 10004.899999000001, 10007.100006999994, 10006.400001999997]\n",
      "Total Portfolio value in episodes[9999.9, 10000.0, 10000.0, 10000.0, 10003.500002999997, 10000.199999999999, 9994.300001000001, 9998.9, 10002.700003999997, 10000.0, 9998.9, 10000.3, 10005.300003999995, 9987.600006999995, 10000.0, 9998.9, 10708.350011999994, 10000.0, 10000.0, 10004.100002, 10000.0, 11257.00000899999, 10000.0, 10000.0, 10000.300006999994, 10000.0, 10000.0, 10000.0, 10000.0, 10000.9, 9996.599998999998, 10000.0, 9998.9, 10001.4, 10001.5, 10000.6, 10000.700004999997, 10000.0, 10006.300003, 10000.0, 10000.0, 10000.0, 9999.700002, 9999.9, 10004.4, 10000.0, 10005.2, 9998.9, 10000.0, 10000.0, 10000.0, 10002.2, 10000.0, 10710.450003999997, 10000.9, 10000.0, 10000.0, 10011.999998000001, 10000.0, 10000.0, 10000.900001, 10000.0, 10000.0, 10000.0, 10000.0, 10767.150006000002, 10000.0, 10007.899998000003, 10000.0, 10000.0, 10000.199996000003, 10003.5, 10016.999999, 10438.700006999992, 10004.299997000002, 10000.0, 10001.700003999998, 10000.0, 10000.099999, 9999.299999, 10390.750003999989, 10000.0, 10000.0, 10010.5, 9998.9, 10001.599999000002, 10000.0, 9999.600000999999, 10001.4, 10000.0, 10000.0, 9998.9, 10000.0, 10004.899999000003, 10000.0, 9991.300017999985, 10383.400000000005, 10535.550034999995, 10004.899999000001, 10007.100006999994, 10006.400001999997]\n",
      "------------------------------\n",
      "Total Days in episodes[6, 0, 1, 0, 14, 6, 112, 2, 107, 0, 5, 5, 20, 54, 0, 2, 730, 3, 1, 17, 1, 730, 0, 0, 105, 0, 1, 1, 0, 4, 226, 0, 2, 5, 4, 3, 49, 0, 30, 1, 0, 0, 43, 6, 16, 0, 14, 3, 0, 0, 0, 6, 1, 730, 4, 0, 0, 108, 1, 2, 9, 1, 4, 0, 1, 730, 0, 20, 0, 1, 104, 6, 46, 730, 107, 1, 15, 0, 9, 10, 730, 1, 0, 23, 2, 15, 0, 12, 4, 0, 0, 2, 0, 11, 0, 184, 730, 730, 8, 115, 51]\n",
      "Benchmark_Profit is  12640   with remaining Apple Stocks: 8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Apple stocks in episodes\"+ str(total_stock1bal))\n",
    "print(\"///////\")\n",
    "# print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "print(\"Total Open cash in episodes\"+ str(total_open_cash))\n",
    "print(\"Total Portfolio value in episodes\"+ str(total_port_value))\n",
    "print(\"------------------------------\")\n",
    "print(\"Total Days in episodes\"+ str(total_days_played))\n",
    "\n",
    "print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "[[-2631.9841 -1070.4501  2292.6062]]\n",
      "2\n",
      "[[-2632.0227 -1070.5747  2292.6143]]\n",
      "2\n",
      "[[-2632.0017 -1070.5066  2292.61  ]]\n",
      "2\n",
      "[[-2631.952  -1070.3483  2292.5984]]\n",
      "2\n",
      "[[-2631.9458 -1070.3254  2292.5981]]\n",
      "2\n",
      "[[-2631.9546 -1070.3367  2292.606 ]]\n",
      "2\n",
      "[[-2631.972  -1070.3473  2292.6243]]\n",
      "2\n",
      "[[-2631.9866 -1070.3014  2292.6577]]\n",
      "2\n",
      "[[-2632.0366 -1070.3801  2292.695 ]]\n",
      "2\n",
      "[[-2632.0325 -1070.3802  2292.69  ]]\n",
      "2\n",
      "[[-2632.0076 -1070.324   2292.677 ]]\n",
      "2\n",
      "[[-2632.0059 -1070.3125  2292.6782]]\n",
      "2\n",
      "[[-2632.01   -1070.3125  2292.683 ]]\n",
      "2\n",
      "[[-2632.0085 -1070.3124  2292.6816]]\n",
      "2\n",
      "[[-2631.9995 -1070.2555  2292.689 ]]\n",
      "2\n",
      "[[-2631.9763 -1070.1306  2292.7002]]\n",
      "2\n",
      "[[-2631.9795 -1070.0619  2292.7263]]\n",
      "2\n",
      "[[-2632.011  -1070.0612  2292.766 ]]\n",
      "2\n",
      "[[-2632.0557 -1070.1053  2292.8088]]\n",
      "2\n",
      "[[-2632.081  -1070.1047  2292.8418]]\n",
      "2\n",
      "[[-2632.0718 -1070.0138  2292.8594]]\n",
      "2\n",
      "[[-2632.051  -1069.9001  2292.8704]]\n",
      "2\n",
      "[[-2632.0886 -1069.9564  2292.899 ]]\n",
      "2\n",
      "[[-2632.1328 -1070.058   2292.9219]]\n",
      "2\n",
      "[[-2632.1313 -1070.0349  2292.9277]]\n",
      "2\n",
      "[[-2632.1255 -1069.9894  2292.935 ]]\n",
      "2\n",
      "[[-2632.1355 -1070.012   2292.9402]]\n",
      "2\n",
      "[[-2632.1213 -1070.0126  2292.9224]]\n",
      "2\n",
      "[[-2632.1108 -1070.0013  2292.9126]]\n",
      "2\n",
      "[[-2632.1282 -1070.035   2292.9238]]\n",
      "2\n",
      "[[-2632.1423 -1070.0802  2292.9275]]\n",
      "2\n",
      "[[-2632.1382 -1070.1031  2292.914 ]]\n",
      "2\n",
      "[[-2632.1375 -1070.1377  2292.902 ]]\n",
      "2\n",
      "[[-2632.097  -1070.0587  2292.8767]]\n",
      "2\n",
      "[[-2632.108  -1070.1157  2292.8718]]\n",
      "2\n",
      "[[-2632.0874 -1070.0819  2292.857 ]]\n",
      "2\n",
      "[[-2632.1016 -1070.1272  2292.8599]]\n",
      "2\n",
      "[[-2632.1013 -1070.1385  2292.8564]]\n",
      "2\n",
      "[[-2632.1199 -1070.1952  2292.8608]]\n",
      "2\n",
      "[[-2632.0708 -1070.0939  2292.832 ]]\n",
      "2\n",
      "[[-2632.091  -1070.1503  2292.839 ]]\n",
      "2\n",
      "[[-2632.1035 -1070.2185  2292.8325]]\n",
      "2\n",
      "[[-2632.103  -1070.2527  2292.821 ]]\n",
      "2\n",
      "[[-2632.103  -1070.2985  2292.8057]]\n",
      "2\n",
      "[[-2632.0796 -1070.2649  2292.7874]]\n",
      "2\n",
      "[[-2632.051  -1070.2427  2292.7585]]\n",
      "2\n",
      "[[-2632.0503 -1070.277   2292.7463]]\n",
      "2\n",
      "[[-2632.033  -1070.2433  2292.7354]]\n",
      "2\n",
      "[[-2632.0305 -1070.2318  2292.736 ]]\n",
      "2\n",
      "[[-2632.0532 -1070.2769  2292.75  ]]\n",
      "2\n",
      "[[-2632.0518 -1070.277   2292.748 ]]\n",
      "2\n",
      "[[-2632.0615 -1070.3224  2292.746 ]]\n",
      "2\n",
      "[[-2632.0208 -1070.2091  2292.7307]]\n",
      "2\n",
      "[[-2632.0352 -1070.2432  2292.7388]]\n",
      "2\n",
      "[[-2632.0305 -1070.2318  2292.736 ]]\n",
      "2\n",
      "[[-2632.019 -1070.175  2292.74 ]]\n",
      "2\n",
      "[[-2632.0527 -1070.2426  2292.7607]]\n",
      "2\n",
      "[[-2632.059  -1070.2312  2292.7722]]\n",
      "2\n",
      "[[-2632.074  -1070.2877  2292.7727]]\n",
      "2\n",
      "[[-2632.0608 -1070.2651  2292.7634]]\n",
      "2\n",
      "[[-2632.1057 -1070.424   2292.7688]]\n",
      "2\n",
      "[[-2632.0642 -1070.3907  2292.7268]]\n",
      "2\n",
      "[[-2632.0142 -1070.2894  2292.6963]]\n",
      "2\n",
      "[[-2632.0068 -1070.2894  2292.6875]]\n",
      "2\n",
      "[[-2632.0107 -1070.3009  2292.688 ]]\n",
      "2\n",
      "[[-2632.006  -1070.3011  2292.6824]]\n",
      "2\n",
      "[[-2632.0251 -1070.3119  2292.7034]]\n",
      "2\n",
      "[[-2632.0317 -1070.3003  2292.7153]]\n",
      "2\n",
      "[[-2632.0308 -1070.3004  2292.7136]]\n",
      "2\n",
      "[[-2632.0046 -1070.2212  2292.7068]]\n",
      "2\n",
      "[[-2632.0388 -1070.3     2292.7244]]\n",
      "2\n",
      "[[-2632.0322 -1070.2775  2292.723 ]]\n",
      "2\n",
      "[[-2632.0432 -1070.3     2292.7302]]\n",
      "2\n",
      "[[-2632.0469 -1070.3115  2292.731 ]]\n",
      "2\n",
      "[[-2632.042  -1070.3     2292.7283]]\n",
      "2\n",
      "[[-2632.0244 -1070.2777  2292.7134]]\n",
      "2\n",
      "[[-2632.0383 -1070.3116  2292.7197]]\n",
      "2\n",
      "[[-2632.0483 -1070.3569  2292.7178]]\n",
      "2\n",
      "[[-2632.041  -1070.3572  2292.7085]]\n",
      "2\n",
      "[[-2632.0283 -1070.3346  2292.7   ]]\n",
      "2\n",
      "[[-2632.034  -1070.3684  2292.696 ]]\n",
      "2\n",
      "[[-2632.02   -1070.3579  2292.6816]]\n",
      "2\n",
      "[[-2632.0103 -1070.3466  2292.673 ]]\n",
      "2\n",
      "[[-2632.008  -1070.3352  2292.674 ]]\n",
      "2\n",
      "[[-2632.0146 -1070.3464  2292.6787]]\n",
      "2\n",
      "[[-2632.0205 -1070.3693  2292.6785]]\n",
      "2\n",
      "[[-2632.0137 -1070.3467  2292.6768]]\n",
      "2\n",
      "[[-2632.0076 -1070.324   2292.677 ]]\n",
      "2\n",
      "[[-2632.0144 -1070.3351  2292.6816]]\n",
      "2\n",
      "[[-2632.0212 -1070.3575  2292.683 ]]\n",
      "2\n",
      "[[-2631.978  -1070.2218  2292.6724]]\n",
      "2\n",
      "[[-2631.989  -1070.1987  2292.6943]]\n",
      "2\n",
      "[[-2631.9895 -1070.1415  2292.7136]]\n",
      "2\n",
      "[[-2632.0266 -1070.1863  2292.7458]]\n",
      "2\n",
      "[[-2632.073  -1070.2765  2292.7751]]\n",
      "2\n",
      "[[-2632.0935 -1070.31    2292.7903]]\n",
      "2\n",
      "[[-2632.0574 -1070.2312  2292.7708]]\n",
      "2\n",
      "[[-2632.0637 -1070.2653  2292.767 ]]\n",
      "2\n",
      "[[-2632.0342 -1070.2203  2292.7441]]\n",
      "2\n",
      "[[-2632.0159 -1070.175   2292.7358]]\n",
      "2\n",
      "[[-2632.0361 -1070.1974  2292.754 ]]\n",
      "2\n",
      "[[-2632.0464 -1070.1857  2292.771 ]]\n",
      "2\n",
      "[[-2632.0347 -1070.1289  2292.7747]]\n",
      "2\n",
      "[[-2632.0483 -1070.1172  2292.796 ]]\n",
      "2\n",
      "[[-2632.0537 -1070.0941  2292.8103]]\n",
      "2\n",
      "[[-2632.043  -1070.0261  2292.8188]]\n",
      "2\n",
      "[[-2632.071  -1070.0482  2292.8472]]\n",
      "2\n",
      "[[-2632.1055 -1070.1041  2292.8726]]\n",
      "2\n",
      "[[-2632.1084 -1070.1041  2292.876 ]]\n",
      "2\n",
      "[[-2632.0925 -1070.0474  2292.874 ]]\n",
      "2\n",
      "[[-2632.0908 -1070.0245  2292.8801]]\n",
      "2\n",
      "[[-2632.1714 -1070.285   2292.8972]]\n",
      "2\n",
      "[[-2632.1455 -1070.2975  2292.8604]]\n",
      "2\n",
      "[[-2632.104  -1070.2416  2292.826 ]]\n",
      "2\n",
      "[[-2632.09   -1070.2528  2292.8044]]\n",
      "2\n",
      "[[-2632.0474 -1070.1971  2292.768 ]]\n",
      "2\n",
      "[[-2632.0225 -1070.1864  2292.7402]]\n",
      "2\n",
      "[[-2632.0386 -1070.1974  2292.7576]]\n",
      "2\n",
      "[[-2632.0342 -1070.1405  2292.7703]]\n",
      "2\n",
      "[[-2632.054  -1070.1627  2292.7876]]\n",
      "2\n",
      "[[-2632.0508 -1070.1171  2292.7988]]\n",
      "2\n",
      "[[-2632.0647 -1070.1283  2292.8127]]\n",
      "2\n",
      "[[-2632.0715 -1070.128   2292.8215]]\n",
      "2\n",
      "[[-2632.083  -1070.1388  2292.8328]]\n",
      "2\n",
      "[[-2632.0903 -1070.1617  2292.8347]]\n",
      "2\n",
      "[[-2632.08   -1070.1276  2292.8325]]\n",
      "2\n",
      "[[-2632.0713 -1070.105   2292.829 ]]\n",
      "2\n",
      "[[-2632.0603 -1070.0598  2292.8293]]\n",
      "2\n",
      "[[-2632.0825 -1070.1046  2292.8433]]\n",
      "2\n",
      "[[-2632.122  -1070.2178  2292.8567]]\n",
      "2\n",
      "[[-2632.1184 -1070.2295  2292.8477]]\n",
      "2\n",
      "[[-2632.1128 -1070.2526  2292.8337]]\n",
      "2\n",
      "[[-2632.0981 -1070.2642  2292.811 ]]\n",
      "2\n",
      "[[-2632.0903 -1070.3217  2292.7822]]\n",
      "2\n",
      "[[-2632.0488 -1070.2769  2292.7446]]\n",
      "2\n",
      "[[-2632.046  -1070.2886  2292.7363]]\n",
      "2\n",
      "[[-2632.0386 -1070.2888  2292.7273]]\n",
      "2\n",
      "[[-2632.048  -1070.3341  2292.7249]]\n",
      "2\n",
      "[[-2632.0432 -1070.3456  2292.7148]]\n",
      "2\n",
      "[[-2632.0122 -1070.2551  2292.7048]]\n",
      "2\n",
      "[[-2632.0293 -1070.3004  2292.712 ]]\n",
      "2\n",
      "[[-2632.0276 -1070.3005  2292.7097]]\n",
      "2\n",
      "[[-2632.0332 -1070.3231  2292.7097]]\n",
      "2\n",
      "[[-2632.0347 -1070.3232  2292.7112]]\n",
      "2\n",
      "[[-2632.0483 -1070.3569  2292.7178]]\n",
      "2\n",
      "[[-2632.0354 -1070.3572  2292.7014]]\n",
      "2\n",
      "[[-2632.035 -1070.38   2292.693]]\n",
      "2\n",
      "[[-2632.0676 -1070.5165  2292.6904]]\n",
      "2\n",
      "[[-2632.029  -1070.4716  2292.6562]]\n",
      "2\n",
      "[[-2631.99   -1070.4042  2292.6282]]\n",
      "2\n",
      "[[-2632.0608 -1070.6536  2292.6375]]\n",
      "2\n",
      "[[-2632.0037 -1070.5865  2292.587 ]]\n",
      "2\n",
      "[[-2631.999  -1070.6554  2292.5586]]\n",
      "2\n",
      "[[-2631.9678 -1070.6105  2292.533 ]]\n",
      "2\n",
      "[[-2631.9722 -1070.6788  2292.5166]]\n",
      "2\n",
      "[[-2631.9414 -1070.691   2292.4734]]\n",
      "2\n",
      "[[-2631.9268 -1070.6571  2292.466 ]]\n",
      "2\n",
      "[[-2631.8901 -1070.5668  2292.449 ]]\n",
      "2\n",
      "[[-2631.8838 -1070.5099  2292.459 ]]\n",
      "2\n",
      "[[-2631.9072 -1070.5436  2292.478 ]]\n",
      "2\n",
      "[[-2631.9102 -1070.4976  2292.4973]]\n",
      "2\n",
      "[[-2631.9414 -1070.5198  2292.5293]]\n",
      "2\n",
      "[[-2631.944  -1070.4739  2292.5479]]\n",
      "2\n",
      "[[-2631.9626 -1070.4963  2292.5637]]\n",
      "2\n",
      "[[-2631.9675 -1070.5078  2292.5662]]\n",
      "2\n",
      "[[-2631.9714 -1070.5074  2292.5715]]\n",
      "2\n",
      "[[-2631.9424 -1070.4169  2292.5637]]\n",
      "2\n",
      "[[-2631.948  -1070.3939  2292.5784]]\n",
      "2\n",
      "[[-2631.9512 -1070.3711  2292.59  ]]\n",
      "2\n",
      "[[-2631.9875 -1070.4387  2292.6143]]\n",
      "2\n",
      "[[-2632.0308 -1070.5514  2292.6328]]\n",
      "2\n",
      "[[-2632.015  -1070.5176  2292.6228]]\n",
      "2\n",
      "[[-2631.9849 -1070.4614  2292.6035]]\n",
      "2\n",
      "[[-2631.9724 -1070.4503  2292.5916]]\n",
      "2\n",
      "[[-2631.9731 -1070.4846  2292.5808]]\n",
      "2\n",
      "[[-2631.9534 -1070.4393  2292.5703]]\n",
      "2\n",
      "[[-2631.9922 -1070.5184  2292.5942]]\n",
      "2\n",
      "[[-2631.982  -1070.4844  2292.592 ]]\n",
      "2\n",
      "[[-2631.9685 -1070.4503  2292.5864]]\n",
      "2\n",
      "[[-2631.9717 -1070.4618  2292.5867]]\n",
      "2\n",
      "[[-2631.982  -1070.4844  2292.592 ]]\n",
      "2\n",
      "[[-2631.9692 -1070.462   2292.5833]]\n",
      "2\n",
      "[[-2631.9622 -1070.4164  2292.5889]]\n",
      "2\n",
      "[[-2631.974  -1070.4275  2292.6006]]\n",
      "2\n",
      "[[-2631.9663 -1070.3933  2292.602 ]]\n",
      "2\n",
      "[[-2631.947  -1070.3026  2292.6067]]\n",
      "2\n",
      "[[-2631.963  -1070.2794  2292.6345]]\n",
      "2\n",
      "[[-2631.985  -1070.2789  2292.663 ]]\n",
      "2\n",
      "[[-2631.9985 -1070.2668  2292.684 ]]\n",
      "2\n",
      "[[-2632.0151 -1070.2551  2292.709 ]]\n",
      "2\n",
      "[[-2632.046  -1070.2999  2292.7334]]\n",
      "2\n",
      "[[-2632.039  -1070.2772  2292.732 ]]\n",
      "2\n",
      "[[-2632.0325 -1070.2549  2292.7305]]\n",
      "2\n",
      "[[-2632.0137 -1070.1868  2292.7292]]\n",
      "2\n",
      "[[-2632.0237 -1070.1864  2292.7422]]\n",
      "2\n",
      "[[-2632.0535 -1070.254   2292.7578]]\n",
      "2\n",
      "[[-2632.0452 -1070.2086  2292.7617]]\n",
      "2\n",
      "[[-2632.0532 -1070.2083  2292.7725]]\n",
      "2\n",
      "[[-2632.0554 -1070.1969  2292.779 ]]\n",
      "2\n",
      "[[-2632.0544 -1070.1969  2292.7776]]\n",
      "2\n",
      "[[-2632.0635 -1070.2311  2292.7778]]\n",
      "2\n",
      "[[-2632.0662 -1070.231   2292.7815]]\n",
      "2\n",
      "[[-2632.074  -1070.265   2292.7803]]\n",
      "2\n",
      "[[-2632.0562 -1070.2311  2292.7686]]\n",
      "2\n",
      "[[-2632.031  -1070.1633  2292.7588]]\n",
      "2\n",
      "[[-2632.0356 -1070.1633  2292.7644]]\n",
      "2\n",
      "[[-2632.0369 -1070.1403  2292.7734]]\n",
      "2\n",
      "[[-2632.0447 -1070.1288  2292.7874]]\n",
      "2\n",
      "[[-2632.0613 -1070.1283  2292.8083]]\n",
      "2\n",
      "[[-2632.078  -1070.1393  2292.8262]]\n",
      "2\n",
      "[[-2632.0703 -1070.1051  2292.8276]]\n",
      "2\n",
      "[[-2632.095  -1070.1615  2292.8403]]\n",
      "2\n",
      "[[-2632.085  -1070.1389  2292.8352]]\n",
      "2\n",
      "[[-2632.083  -1070.1388  2292.8328]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[-2632.065  -1070.0826  2292.8276]]\n",
      "2\n",
      "[[-2632.061  -1070.0483  2292.8342]]\n",
      "2\n",
      "[[-2632.0645 -1070.0367  2292.842 ]]\n",
      "2\n",
      "[[-2632.0732 -1070.0138  2292.861 ]]\n",
      "2\n",
      "[[-2632.064  -1069.934   2292.8752]]\n",
      "2\n",
      "[[-2632.1038 -1069.9786  2292.9114]]\n",
      "2\n",
      "[[-2632.12   -1069.9896  2292.9282]]\n",
      "2\n",
      "[[-2632.1519 -1070.0687  2292.9426]]\n",
      "2\n",
      "[[-2632.154  -1070.0917  2292.938 ]]\n",
      "2\n",
      "[[-2632.158  -1070.137   2292.9285]]\n",
      "2\n",
      "[[-2632.105  -1070.0471  2292.8906]]\n",
      "2\n",
      "[[-2632.0793 -1069.9908  2292.876 ]]\n",
      "2\n",
      "[[-2632.0718 -1069.9683  2292.8738]]\n",
      "2\n",
      "[[-2632.0955 -1070.0017  2292.8923]]\n",
      "2\n",
      "[[-2632.1028 -1069.9902  2292.906 ]]\n",
      "2\n",
      "[[-2632.1213 -1069.9896  2292.9292]]\n",
      "2\n",
      "[[-2632.1284 -1069.9894  2292.9392]]\n",
      "2\n",
      "[[-2632.1252 -1069.9781  2292.939 ]]\n",
      "2\n",
      "[[-2632.1162 -1069.9553  2292.9346]]\n",
      "2\n",
      "[[-2632.1155 -1069.9327  2292.9404]]\n",
      "2\n",
      "[[-2632.0947 -1069.8422  2292.9436]]\n",
      "2\n",
      "[[-2632.1055 -1069.8186  2292.9653]]\n",
      "2\n",
      "[[-2632.1196 -1069.7955  2292.991 ]]\n",
      "2\n",
      "[[-2632.0974 -1069.6477  2293.0107]]\n",
      "2\n",
      "[[-2632.1284 -1069.6241  2293.0579]]\n",
      "2\n",
      "[[-2632.1912 -1069.7023  2293.1118]]\n",
      "2\n",
      "[[-2632.194  -1069.6565  2293.1306]]\n",
      "2\n",
      "[[-2632.2239 -1069.69    2293.1572]]\n",
      "2\n",
      "[[-2632.241  -1069.7012  2293.1753]]\n",
      "2\n",
      "[[-2632.2092 -1069.622   2293.161 ]]\n",
      "2\n",
      "[[-2632.2197 -1069.6559  2293.1633]]\n",
      "2\n",
      "Total Apple stocks in episodes0\n",
      "///////\n",
      "Total Open cash in episodes10000\n",
      "Total Portfolio value in episodes10000.0\n",
      "------------------------------\n",
      "Total Days in episodes244\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "pd_data1_test=pd_data1_test.reset_index(drop=True)\n",
    "data1_test=pd_data1_test['Close']\n",
    "#Training run\n",
    "\n",
    "import csv\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model_name='model_ep90'\n",
    "\n",
    "model = load_model(\"models/\" + model_name)\n",
    "\n",
    "initial_cash = state_class_obj.portfolio_value\n",
    "#Define arrays to store per episode values \n",
    "total_Prof=[]\n",
    "total_stock1bal=[]\n",
    "# total_stock2bal=[]\n",
    "total_open_cash=[]\n",
    "total_port_value=[]\n",
    "total_days_played=[]\n",
    "\n",
    "for e in range(1):\n",
    "    print(\"..........\")\n",
    "    \n",
    "    Bal_stock1=int(0)\n",
    "    open_cash=start_balance\n",
    "    datasize=test\n",
    "    done=False\n",
    "    total_profit = 0\n",
    "    reward = 0\n",
    "    \n",
    "    #Initialize Agent\n",
    "#     agent = Agent(5)\n",
    "    agent = Agent(5, is_eval=True, model_name=model_name)\n",
    "    agent.inventory1 =[]\n",
    "    open_cash_t1=open_cash\n",
    "    for i in range(Bal_stock1):\n",
    "        agent.inventory1.append(data1_train[0])\n",
    "        \n",
    "    Bal_stock1_t1 = len(agent.inventory1)\n",
    "    \n",
    "    #Running episode over all days in the datasize\n",
    "    for t in range(datasize):\n",
    "#         print(datasize)\n",
    "        #print(pd_data1_train.iloc[t,0])\n",
    "        state_class_obj= State(data1_train, Bal_stock1, open_cash,t)\n",
    "        state_array_obj=state_class_obj.getState()\n",
    "        action = agent.act(state_array_obj)\n",
    "        print(action)           \n",
    "        change_percent_stock1=(state_class_obj.Stock1Price-state_class_obj.fiveday_stock1)/state_class_obj.fiveday_stock1*100\n",
    "#         change_percent_stock2=(state_class_obj.Stock2Price-state_class_obj.fiveday_stock2)/state_class_obj.fiveday_stock2*100\n",
    "        \n",
    "        #print(\"change_percent_stock1:  \"+str(change_percent_stock1))\n",
    "        #print(\"change_percent_stock2:  \"+str(change_percent_stock2))\n",
    "        \n",
    "        \n",
    "        if action == 0:  #buy stock 1\n",
    "            if state_class_obj.Stock1Price > state_class_obj.open_cash:\n",
    "                '''\n",
    "                print(\"Buy stock 1 when it did not have cash, so bankrupt, end of episode\")\n",
    "                reward=-reward_timedelta*10\n",
    "                done = True\n",
    "                '''\n",
    "                #If agent is trying to buy when it has no cash but has stock1 and stock2 balance then, \n",
    "                #it should pick from other actions\n",
    "                #if (state_class_obj.Stock1Blnc>1) and  (state_class_obj.Stock2Blnc>1):\n",
    "                 #   action=random.sample([1, 2, 4, 5, 6],  1)  # Choose 1 elements from sell actions\n",
    "                #else:    \n",
    "                #print(\"Bankrupt\")\n",
    "#                 reward=-200000\n",
    "                done = True\n",
    "                #end episode\n",
    "                     \n",
    "            else:\n",
    "                #print(\"In Buy stock 1\")\n",
    "                agent.inventory1.append(data1_train[t])\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash-state_class_obj.Stock1Price #Here we are buying 1 stock\n",
    "                \n",
    "                #needs to be reviewed\n",
    "#                 if(Bal_stock1_t1 == 0):\n",
    "#                     reward = 300000\n",
    "#                 elif(state_class_obj.open_cash<500):\n",
    "#                     reward=-100000\n",
    "#                 elif (state_class_obj.Stock1Price > state_class_obj.fiveday_stock1):\n",
    "#                     reward+=1000\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=-10000\n",
    "#                 else:  \n",
    "#                     reward=-change_percent_stock1*100\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "        if action == 1:  #sell stock 1\n",
    "            if state_class_obj.Stock1Blnc <1 :\n",
    "               # print(\"sold stock 2 when it did not have stock 2, so bankrupt, end of episode\")\n",
    "#                 reward=-5000000\n",
    "                done = True\n",
    "                #end episode\n",
    "            else:\n",
    "                #print(\"In sell stock 1\")\n",
    "                bought_price1=agent.inventory1.pop(0)\n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "                Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=state_class_obj.open_cash+state_class_obj.Stock1Price #State[0] is the price of stock 1. Here we are buying 1 stoc\n",
    "                #total_profit += data1_train[t] - bought_price1\n",
    "            #print(\"reward for sell stock1 \" + str(reward))\n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "#        TODO Config logic in this Action \n",
    "        if action == 2:             # Do nothing action    \n",
    "#                 if (abs(change_percent_stock1)<=2):\n",
    "# #                     reward=10000\n",
    "#                 elif (state_class_obj.open_cash<0.1*start_balance):\n",
    "#                     reward=-1000000\n",
    "#                 elif (abs(change_percent_stock1)<=2):\n",
    "#                     reward=1000\n",
    "#                 else:\n",
    "#                     reward=-100000\n",
    "                \n",
    "                Bal_stock1_t1= len(agent.inventory1)\n",
    "#                 Bal_stock2_t1=len(agent.inventory2)\n",
    "                open_cash_t1=open_cash\n",
    "               # print(\"Do nothing\")\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(\"reward:  \"+str(reward))\n",
    "        #if done!= False:done = True if t == datasize\n",
    "        if t == datasize-1:\n",
    "            #print(\"t==datasize\")\n",
    "            done=True\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "        else:\n",
    "            next_state_class_obj=State(data1_train, Bal_stock1_t1, open_cash_t1,t+1)\n",
    "            next_state_array_obj=next_state_class_obj.getState()\n",
    "            \n",
    "        agent.memory.append((state_array_obj, action, reward, next_state_array_obj, done))\n",
    "        #print(\"Action is \"+str(action)+\" reward is\" + str(reward))\n",
    "         \n",
    "        Bal_stock1=Bal_stock1_t1\n",
    "#         Bal_stock2= Bal_stock2_t1\n",
    "        open_cash=open_cash_t1\n",
    "        \n",
    "        \n",
    "      #  print(\"total_profit on day basis \" + str(total_profit) +\"on day\"+str(t) + \"stock 1 number: \" + \n",
    "        #      str(len(agent.inventory1))+\"/\"+str(next_state_class_obj.Stock1Blnc)+\" stock2 number:\"+\n",
    "         #         str(len(agent.inventory2)) +\"/\"+str(next_state_class_obj.Stock2Blnc)+\n",
    "          #        \"open cash: \"+str(next_state_class_obj.open_cash))\n",
    "        \n",
    "       # print(\"doneAction\" + str(done))\n",
    "       # print(\"--------------------------------\") \n",
    "       \n",
    "        \n",
    "        \n",
    "        if done==True:\n",
    "            #print(\"--------------------------------\")\n",
    "           # print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "           # print(\"Total No. of days played: \" + str(t)+ \"  out of overall days:  \" + str(datasize))\n",
    "           # print(\"Total portfolio value: \" + str(next_state_class_obj.portfolio_value)+ \n",
    "             #     \"  stock 1 number: \" + str(len(agent.inventory1))\n",
    "            #      +\"  stock 2 number: \"+str(len(agent.inventory2))+\"  open cash\"+str(next_state_class_obj.open_cash))\n",
    "\n",
    "            print(\"Total Apple stocks in episodes\"+ str(Bal_stock1))\n",
    "            print(\"///////\")\n",
    "            # print(\"Total Amazon stocks in episodes\"+ str(total_stock2bal))\n",
    "            print(\"Total Open cash in episodes\"+ str(open_cash))\n",
    "            print(\"Total Portfolio value in episodes\"+ str(state_class_obj.portfolio_value))\n",
    "            print(\"------------------------------\")\n",
    "            print(\"Total Days in episodes\"+ str(t))\n",
    "\n",
    "#             print(\"Benchmark_Profit is  \" + str(int(Training_Benchmark_Portfolio_Value)) +\"   with remaining Apple Stocks: \" + str(remaining_stock1))\n",
    "# #             if len(agent.memory) <= batch_size:\n",
    "#                 print(\"^_^\")\n",
    "#                 agent.expReplay(len(agent.memory))\n",
    "\n",
    "\n",
    "            print(\"--------------------------------\")\n",
    "#             state_class_obj.reset()\n",
    "            break\n",
    "           \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
